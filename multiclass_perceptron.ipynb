{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbasecondaf2502c8d509343d8b7a2a5333aef9413",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;\\nTHIS IS A WORKING PERCEPTRON OF A BINARY CLASSIFICIATION\\n&#39;"
     },
     "metadata": {},
     "execution_count": 511
    }
   ],
   "source": [
    "'''\n",
    "CISC 452 Perceptron\n",
    "Harry Kim \n",
    "20047381\n",
    "same code as multiclass_perceptron but using the pocket algorithim\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#libararies that allow easier handling of the data and visualization. Not importing anything for the model itself. \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "import random as random \n",
    "\n",
    "#data preprocessing\n",
    "train_set = open(\"iris_train.txt\",\"r\")\n",
    "test_set = open('iris_test.txt','r')\n",
    "\n",
    "def preprocess(data):\n",
    "    df = pd.DataFrame(columns=['sepal_length','sepal_width','petal_lenght','petal_width','iris_type'])\n",
    "\n",
    "    #cleaning up data and putting it in df\n",
    "    for i in data:\n",
    "        i = i.strip()   #get rid of \\n \n",
    "        lst= i.split(\",\") #split the string into list\n",
    "        df = df.append({'sepal_length':float(lst[0]), 'sepal_width':float(lst[1]),'petal_lenght':float(lst[2]),'petal_width':float(lst[3]),'iris_type':lst[4]},ignore_index=True)\n",
    "\n",
    "    #since the target label has three string type categorical data, we will turn it into numerical using label encoder\n",
    "    df['iris_type']= LabelEncoder().fit_transform(df['iris_type']) #need to turn it into label encoder to turn it into one hot\n",
    "    df =pd.get_dummies(df, columns = ['iris_type']) #one hot encoding\n",
    "    return df \n",
    "\n",
    "df_train = preprocess(train_set)\n",
    "df_test = preprocess(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization DONT RUN FOR MARKING, EXPENSIVE TO RUN\n",
    "# iris = df.copy()\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# attributes = ['sepal_length','sepal_width','petal_lenght','petal_width'] \n",
    "# iris = iris[attributes].astype(np.float)\n",
    "\n",
    "# # iris.hist(bins=50, figsize=(20,15)) \n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def min_max(df):\n",
    "    y = df.iloc[:,4:]\n",
    "    x = df.iloc[:,0:4].values #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_ = pd.DataFrame(x_scaled)\n",
    "    df_ = df_.join(y)\n",
    "    return df_\n",
    "\n",
    "# df_train = min_max(df_train)\n",
    "# df_test = min_max(df_test)\n",
    "\n",
    "# print(df_train)"
   ]
  },
  {
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, epoch=100, c=0.1):\n",
    "        self.epoch = epoch\n",
    "        self.c = c  #learning rate\n",
    "        self.weights = self.random_weights() #creates an np array of zeros, +1 is from the x0=1 bias vector ###make this random instead\n",
    "    \n",
    "    def random_weights(self):\n",
    "        #creates random weights\n",
    "        rand_array = [0] #first weight of 0 that is from the bias\n",
    "        #Four input nodes, four weights\n",
    "        for i in range(4):\n",
    "            rand_array.append(random.uniform(-1, 1))\n",
    "        return np.asarray(rand_array)\n",
    "\n",
    "\n",
    "    def activation(self, x):\n",
    "        #the weights[0] is the bias . The dot product finds the net input (sigma wx) \n",
    "        return np.dot(x, self.weights[1:]) + self.weights[0]\n",
    "\n",
    "    def predict(self, x):\n",
    "        #predict y - f(sigma(xw))\n",
    "        return np.where(self.activation(x) >= 0.0, 1, 0)\n",
    "\n",
    "    def learning(self, d, y, x):\n",
    "        #feeback learning \n",
    "        if y > d: #y =1 d = 0 \n",
    "            self.weights[1:] = self.weights[1:] - self.c * x #adjusting the weights\n",
    "            self.weights[0] = self.weights[0] - self.c #adjust the bias, x is 1 no need to put it in\n",
    "\n",
    "        elif y < d: #y= 0 d = 1\n",
    "            self.weights[1:] = self.weights[1:] + self.c * x\n",
    "            self.weights [0] = self.weights[0] + self.c \n",
    "\n",
    "\n",
    "    def fit(self, total_x, total_d): \n",
    "        turn = int(self.epoch) \n",
    "        for _ in range(turn):\n",
    "            for x, d in zip(total_x, total_d): #zip creates list at (x[n],y[n]) for all values in x and y, iterable\n",
    "                y = self.predict(x)\n",
    "                self.learning(int(d),int(y),x)\n",
    "                "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 514,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiclass_Perceptron:\n",
    "    def __init__(self, epoch = 100, c= 0.1):\n",
    "        #each perceptron does binary classification for their corresponding flowers\n",
    "        self.output1 = Perceptron(epoch,c) \n",
    "        self.output2 = Perceptron(epoch,c) \n",
    "        self.output3 = Perceptron(epoch,c) \n",
    "\n",
    "    def predict(self, x):\n",
    "        output1_pred = self.output1.predict(x.values) #this will be a list of all prediction just for the one corresponding column \n",
    "        output2_pred = self.output2.predict(x.values)\n",
    "        output3_pred = self.output3.predict(x.values)\n",
    "\n",
    "        #format it as a list of list \n",
    "        aList = []\n",
    "        for i in range(len(x)):\n",
    "            bList= [output1_pred[i],output2_pred[i],output3_pred[i]]\n",
    "            aList.append(bList)\n",
    "        return np.array(aList)\n",
    "\n",
    "    def fit(self, total_x, total_d): \n",
    "        #.values converts the pandas column into numpyarray \n",
    "        #.iloc grabs the corresponding binary class column for each \n",
    "        self.output1.fit(total_x.values, total_d.iloc[ : ,0].values) #train binary classification for flower 1\n",
    "        self.output2.fit(total_x.values, total_d.iloc[ : ,1].values) #train binary classification for flower 2\n",
    "        self.output3.fit(total_x.values, total_d.iloc[ : ,2].values) #train binary classification for flower 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1 0 0]\n[1 0 0]\n[1 0 0]\n[1 0 0]\n[1 0 0]\n[1 0 0]\n[1 0 0]\n[1 0 0]\n[1 1 0]\n[1 1 0]\n[0 1 0]\n[0 0 0]\n[0 1 0]\n[0 1 0]\n[0 0 0]\n[0 0 0]\n[0 1 0]\n[0 1 0]\n[0 1 0]\n[0 1 0]\n[0 0 0]\n[0 1 1]\n[0 1 0]\n[0 1 1]\n[0 0 0]\n[0 0 1]\n[0 1 0]\n[0 1 0]\n[0 0 1]\n[0 0 1]\nData: sepal_length    4.4\nsepal_width     2.9\npetal_lenght    1.4\npetal_width     0.2\nName: 8, dtype: float64\nActual: [1 0 0] predicted: [1 1 0]\nData: sepal_length    4.9\nsepal_width     3.1\npetal_lenght    1.5\npetal_width     0.1\nName: 9, dtype: float64\nActual: [1 0 0] predicted: [1 1 0]\nData: sepal_length    6.4\nsepal_width     2.8\npetal_lenght    5.6\npetal_width     2.1\nName: 21, dtype: float64\nActual: [0 0 1] predicted: [0 1 1]\nData: sepal_length    7.4\nsepal_width     2.8\npetal_lenght    6.1\npetal_width     1.9\nName: 23, dtype: float64\nActual: [0 0 1] predicted: [0 1 1]\n"
    }
   ],
   "source": [
    "#partitioning data into target and predictors for training \n",
    "\n",
    "df_train = df_train.sample(frac=1) #randomize the rows for training \n",
    "y_train = df_train.iloc[:, 4:7] #grab the class label \n",
    "x_train = df_train.iloc[:, 0:4] #grab the predictors\n",
    "\n",
    "y_test = df_test.iloc[:, 4:7].values #grab the class label \n",
    "x_test = df_test.iloc[:, 0:4] #grab the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "classifier = Multiclass_Perceptron(epoch = 1000, c= 0.5)\n",
    "classifier.fit(x_train,y_train) \n",
    "\n",
    "#predict\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "#find data points that are classified into multiple classes\n",
    "multiple_pred_index = [] \n",
    "for i in range(len(y_pred)):\n",
    "    output = y_pred[i]\n",
    "    print(output)\n",
    "    x = output[0] + output[1] + output[2]\n",
    "    if x > 1:\n",
    "        multiple_pred_index.append(i)\n",
    "\n",
    "#Grab the corresponding data from test set\n",
    "for i in multiple_pred_index:\n",
    "    print(\"Data:\",x_test.iloc[i])\n",
    "    print('Actual:', y_test[i], \"predicted:\",y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "accuracy 0.6\nconfusion matrix [[[20  0]\n  [ 0 10]]\n\n [[13  7]\n  [ 3  7]]\n\n [[20  0]\n  [ 5  5]]]\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m&lt;ipython-input-517-7074c6f0aa60&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(&#39;recall&#39;, recall_score(y_test,y_pred))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&#39;confusion matrix&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----&gt; 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&#39;confusion matrix&#39;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m&quot;binary&quot;\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m&quot;multiclass&quot;\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--&gt; 270\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m&quot;%s is not supported&quot;\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "#Getting Accuracy and Confusion Matrix\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "print(\"accuracy\", accuracy_score(y_test,y_pred))\n",
    "print('confusion matrix', multilabel_confusion_matrix(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0, 3], [1, 4], [2, 5]]\n"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}